{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julianikulski/director-experience/blob/main/model/baseline_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbj9MbTWBlcA"
      },
      "source": [
        "# Baseline models \n",
        "This file serves two main purposes. First, it creates various baseline models that can be used as a comparison for the performance of the deep learning NLP model which is used to classify director biographies as having environmental and/or social experience. Second, it determines the maximum length that the NLP model needs to accept based on the length of the biographies in the company sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MfSGicswbRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1525b2-4700-4311-bd33-317862c8d573"
      },
      "source": [
        "# connecting to Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtdQex17vcs0"
      },
      "source": [
        "# installing necessary packages\n",
        "!pip install transformers==4.2.2 &> /dev/null\n",
        "!pip install pytorch-lightning==1.2.6 &> /dev/null\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u93VoUThtpvr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import re\n",
        "import math\n",
        "from numpy.random import RandomState\n",
        "from tqdm.notebook import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, AdamW, pipeline\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import torch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izZG25p5tpvx"
      },
      "source": [
        "# diplay columns without truncation\n",
        "pd.set_option('display.max_columns', 500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk5AMqJMaGof"
      },
      "source": [
        "## Reading in reviewed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "207m-q1ZNprh"
      },
      "source": [
        "The review will happen outside of Colab. After I am finished with the manual review, I will upload the file with the two target values here. There are two manual review files. One contains 150 samples from the S&P Capital IQ biographies dataset and one contains an additional 50 samples from the manual DEF 14A review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlTKVL6oN-RA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eea5306-4d68-41fe-aa03-cf25f24c8cad"
      },
      "source": [
        "# read in first review data file\n",
        "bio_excel = pd.ExcelFile('/content/drive/My Drive/director-csr/review_data/train_rev.xlsx')\n",
        "sheet_names = ['reviewed', 'explanations']\n",
        "\n",
        "df_reviewed = {}\n",
        "for sheet in sheet_names:\n",
        "    df_temp = pd.read_excel(bio_excel, sheet) \n",
        "    df_reviewed[sheet] = df_temp\n",
        "\n",
        "df_reviewed.keys()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['reviewed', 'explanations'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "WqTlAfCQA7Ox",
        "outputId": "e9676899-dc72-4434-a694-b53f79178e39"
      },
      "source": [
        "# read in the second review data file\n",
        "bio_50_rev_df = pd.read_excel('/content/drive/My Drive/director-csr/review_data/train_second_rev.xlsx')\n",
        "bio_50_rev_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "bio_50_rev_df.rename(columns={'biographies': 'bio'}, inplace=True)\n",
        "bio_50_rev_df = bio_50_rev_df[['bio', 'social', 'environmental']]\n",
        "bio_50_rev_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bio</th>\n",
              "      <th>social</th>\n",
              "      <th>environmental</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Since February 2014, Ms. Brooks has served as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ms. Mary N. Dillon has been the Chief Executiv...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dr. Lynch, age 55, has served as Chairman and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Irene Miller has served as a member of Coach’s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>John H. Pinkerton became a director in 1988 an...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 bio  social  environmental\n",
              "0  Since February 2014, Ms. Brooks has served as ...       1              0\n",
              "1  Ms. Mary N. Dillon has been the Chief Executiv...       1              0\n",
              "2  Dr. Lynch, age 55, has served as Chairman and ...       0              0\n",
              "3  Irene Miller has served as a member of Coach’s...       0              0\n",
              "4  John H. Pinkerton became a director in 1988 an...       0              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QMa0R9uN3S3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "557e05bf-6db4-4275-bf27-4005ee252da2"
      },
      "source": [
        "# show the list of all reviewed examples\n",
        "df_bio_tags = df_reviewed['reviewed'][['bio', 'social', 'environmental']]\n",
        "df_bio_tags.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bio</th>\n",
              "      <th>social</th>\n",
              "      <th>environmental</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mr. Matthew E. Massengill, also known as Matt,...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mr. Michael H. Dilger, also known as Mick, has...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mr. John R. Hislop has been Chief Executive Of...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mr. John F. Coyne served as the Chief Executiv...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mr. John J. Koraleski, also known as Jack, ser...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 bio  social  environmental\n",
              "0  Mr. Matthew E. Massengill, also known as Matt,...       1              1\n",
              "1  Mr. Michael H. Dilger, also known as Mick, has...       0              0\n",
              "2  Mr. John R. Hislop has been Chief Executive Of...       0              0\n",
              "3  Mr. John F. Coyne served as the Chief Executiv...       0              0\n",
              "4  Mr. John J. Koraleski, also known as Jack, ser...       1              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPNeQSPAByhp",
        "outputId": "0b341c03-d27b-4cbf-cf5a-bb138d3ef677"
      },
      "source": [
        "# combine both review datasets\n",
        "all_rev_df = df_bio_tags.append(bio_50_rev_df)\n",
        "# shape of the dataset\n",
        "len(list(all_rev_df['bio'].unique()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JKQsSOhqRoT"
      },
      "source": [
        "# write the all_rev_df as a csv file so that it can be easily read in the training notebook\n",
        "all_rev_df.to_csv('/content/drive/My Drive/director-csr/review_data/all_200_rev.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-7DbBOvNovO"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "The steps are based on https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification.ipynb#scrollTo=voWiw8C7IrJV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "_QoZMbcSJ8Wv",
        "outputId": "516d85de-30d8-4eff-e067-4b383fe8a99c"
      },
      "source": [
        "# look at the balance of the tags\n",
        "all_rev_df.describe()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>social</th>\n",
              "      <th>environmental</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.335000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.473175</td>\n",
              "      <td>0.300753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           social  environmental\n",
              "count  200.000000     200.000000\n",
              "mean     0.335000       0.100000\n",
              "std      0.473175       0.300753\n",
              "min      0.000000       0.000000\n",
              "25%      0.000000       0.000000\n",
              "50%      0.000000       0.000000\n",
              "75%      1.000000       0.000000\n",
              "max      1.000000       1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqZmBt6PKWgl"
      },
      "source": [
        "# check how many occurences of environmental, social and both tags appear in the dataset\n",
        "def show_share(df):\n",
        "    '''\n",
        "    Function to show the share of occurences of classes in the dataframe\n",
        "    Args: df = dataframe with classes\n",
        "    Returns: df_share = dataframe containing shares\n",
        "    '''\n",
        "    df_share = df.groupby(['environmental', 'social'], as_index=False).count()\n",
        "    df_share['share'] = df_share.apply(lambda x: x['bio'] / len(df), axis=1)\n",
        "    \n",
        "    return df_share\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "UbEnoSLYiVJ-",
        "outputId": "59beae38-76ee-411d-f651-76ccee0a8480"
      },
      "source": [
        "# check the proportions of the original dataset\n",
        "show_share(all_rev_df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>environmental</th>\n",
              "      <th>social</th>\n",
              "      <th>bio</th>\n",
              "      <th>share</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129</td>\n",
              "      <td>0.645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>0.255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0.080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   environmental  social  bio  share\n",
              "0              0       0  129  0.645\n",
              "1              0       1   51  0.255\n",
              "2              1       0    4  0.020\n",
              "3              1       1   16  0.080"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNfKfr4aN3qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210518b0-30e0-436d-9f48-8216b63d3ad9"
      },
      "source": [
        "# split data into training and testing set\n",
        "# because there is only 1 case where environmental is 1 and social is 0, I cannot\n",
        "# stratify the datasets for both columns\n",
        "# I looked at the distribution and this seems to be as close to the original distribution\n",
        "# as possible with a small size like this\n",
        "train_val, test = train_test_split(all_rev_df, test_size=0.2, random_state=42, stratify=all_rev_df['environmental'])\n",
        "train, val = train_test_split(train_val, test_size=0.2, random_state=42, stratify=train_val['environmental'])\n",
        "print(show_share(train_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   environmental  social  bio    share\n",
            "0              0       0  100  0.62500\n",
            "1              0       1   44  0.27500\n",
            "2              1       0    3  0.01875\n",
            "3              1       1   13  0.08125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQYqhlLHRE4S",
        "outputId": "e1f4d081-b6a8-49b8-dcbc-cc3bf06f3510"
      },
      "source": [
        "# check the proportions of the new train, val, and test datasets\n",
        "print(show_share(train))\n",
        "print(show_share(val))\n",
        "print(show_share(test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   environmental  social  bio     share\n",
            "0              0       0   79  0.617188\n",
            "1              0       1   36  0.281250\n",
            "2              1       0    3  0.023438\n",
            "3              1       1   10  0.078125\n",
            "   environmental  social  bio    share\n",
            "0              0       0   21  0.65625\n",
            "1              0       1    8  0.25000\n",
            "2              1       1    3  0.09375\n",
            "   environmental  social  bio  share\n",
            "0              0       0   29  0.725\n",
            "1              0       1    7  0.175\n",
            "2              1       0    1  0.025\n",
            "3              1       1    3  0.075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY9HayVsv7mI"
      },
      "source": [
        "## Reading in entire biography data set for later testing and for pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "gGLbEBLqv7mP",
        "outputId": "b9e65293-c4da-43c9-b655-3867014776c1"
      },
      "source": [
        "# read in file\n",
        "all_bios_df = pd.read_csv('/content/drive/My Drive/director-csr/complete_sample_no_missing.csv')\n",
        "all_bios_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "# remove all duplicate director entries from this dataset\n",
        "all_bios_df_unique = all_bios_df.drop_duplicates(subset=['unique_dir_id'])\n",
        "all_bios_df_unique.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>age</th>\n",
              "      <th>last_position</th>\n",
              "      <th>director_start</th>\n",
              "      <th>director_end</th>\n",
              "      <th>executive_start</th>\n",
              "      <th>executive_end</th>\n",
              "      <th>comp_name</th>\n",
              "      <th>ticker</th>\n",
              "      <th>missing_start_date</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>current_position</th>\n",
              "      <th>dir_exec</th>\n",
              "      <th>in_position</th>\n",
              "      <th>isin</th>\n",
              "      <th>org_name</th>\n",
              "      <th>unique_dir_id</th>\n",
              "      <th>all_years</th>\n",
              "      <th>bio</th>\n",
              "      <th>board_committee</th>\n",
              "      <th>committee</th>\n",
              "      <th>comm_type</th>\n",
              "      <th>comm_start</th>\n",
              "      <th>comm_end</th>\n",
              "      <th>list_years_if_non_consecutive</th>\n",
              "      <th>2011_comm</th>\n",
              "      <th>2012_comm</th>\n",
              "      <th>2013_comm</th>\n",
              "      <th>2014_comm</th>\n",
              "      <th>2015_comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>james mccann</td>\n",
              "      <td>68.0</td>\n",
              "      <td>independent director</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>willis towers watson plc</td>\n",
              "      <td>wltw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie00bdb6q211</td>\n",
              "      <td>mr. james mccann , iii</td>\n",
              "      <td>4129</td>\n",
              "      <td>no</td>\n",
              "      <td>Mr. James F. McCann, also known as Jim, Founde...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jeffrey ubben</td>\n",
              "      <td>58.0</td>\n",
              "      <td>independent director</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>willis towers watson plc</td>\n",
              "      <td>wltw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie00bdb6q211</td>\n",
              "      <td>mr. jeffrey (jeff) ubben</td>\n",
              "      <td>4249</td>\n",
              "      <td>no</td>\n",
              "      <td>Mr. Ubben, age 54, joined the Willis Towers Wa...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dominic casserley</td>\n",
              "      <td>58.0</td>\n",
              "      <td>president, deputy chief executive officer, dir...</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>willis towers watson plc</td>\n",
              "      <td>wltw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie00bdb6q211</td>\n",
              "      <td>mr. dominic casserley</td>\n",
              "      <td>2968</td>\n",
              "      <td>no</td>\n",
              "      <td>Mr. Casserley, age 58, has served as President...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sir roy gardner</td>\n",
              "      <td>NaN</td>\n",
              "      <td>independent director</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>willis towers watson plc</td>\n",
              "      <td>wltw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie00bdb6q211</td>\n",
              "      <td>sir roy gardner</td>\n",
              "      <td>9219</td>\n",
              "      <td>no</td>\n",
              "      <td>Sir Roy Gardner, age 69, joined the Board on A...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sir jeremy hanley</td>\n",
              "      <td>72.0</td>\n",
              "      <td>independent director</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>willis towers watson plc</td>\n",
              "      <td>wltw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie00bdb6q211</td>\n",
              "      <td>sir jeremy hanley</td>\n",
              "      <td>9202</td>\n",
              "      <td>no</td>\n",
              "      <td>Sir Jeremy Hanley, age 69, joined the Board on...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                name   age                                      last_position  \\\n",
              "0       james mccann  68.0                               independent director   \n",
              "1      jeffrey ubben  58.0                               independent director   \n",
              "2  dominic casserley  58.0  president, deputy chief executive officer, dir...   \n",
              "3    sir roy gardner   NaN                               independent director   \n",
              "4  sir jeremy hanley  72.0                               independent director   \n",
              "\n",
              "   director_start  director_end  executive_start  executive_end  \\\n",
              "0             0.0           0.0           2004.0         2019.0   \n",
              "1             0.0           0.0           2013.0         2017.0   \n",
              "2          2013.0        2016.0           2013.0         2016.0   \n",
              "3             0.0           0.0           2006.0         2015.0   \n",
              "4             0.0           0.0           2006.0         2015.0   \n",
              "\n",
              "                  comp_name ticker  missing_start_date  2011  2012  2013  \\\n",
              "0  willis towers watson plc   wltw                 0.0     1     1     1   \n",
              "1  willis towers watson plc   wltw                 0.0     0     0     1   \n",
              "2  willis towers watson plc   wltw                 0.0     0     0     1   \n",
              "3  willis towers watson plc   wltw                 0.0     1     1     1   \n",
              "4  willis towers watson plc   wltw                 0.0     1     1     1   \n",
              "\n",
              "   2014  2015 current_position  dir_exec  in_position          isin  \\\n",
              "0     1     1              NaN       NaN          NaN  ie00bdb6q211   \n",
              "1     1     1              NaN       NaN          NaN  ie00bdb6q211   \n",
              "2     1     1              NaN       NaN          NaN  ie00bdb6q211   \n",
              "3     1     1              NaN       NaN          NaN  ie00bdb6q211   \n",
              "4     1     1              NaN       NaN          NaN  ie00bdb6q211   \n",
              "\n",
              "                   org_name  unique_dir_id all_years  \\\n",
              "0    mr. james mccann , iii           4129        no   \n",
              "1  mr. jeffrey (jeff) ubben           4249        no   \n",
              "2     mr. dominic casserley           2968        no   \n",
              "3           sir roy gardner           9219        no   \n",
              "4         sir jeremy hanley           9202        no   \n",
              "\n",
              "                                                 bio board_committee  \\\n",
              "0  Mr. James F. McCann, also known as Jim, Founde...             NaN   \n",
              "1  Mr. Ubben, age 54, joined the Willis Towers Wa...             NaN   \n",
              "2  Mr. Casserley, age 58, has served as President...             NaN   \n",
              "3  Sir Roy Gardner, age 69, joined the Board on A...             NaN   \n",
              "4  Sir Jeremy Hanley, age 69, joined the Board on...             NaN   \n",
              "\n",
              "  committee comm_type  comm_start  comm_end list_years_if_non_consecutive  \\\n",
              "0       NaN       NaN         NaN       NaN                           NaN   \n",
              "1       NaN       NaN         NaN       NaN                           NaN   \n",
              "2       NaN       NaN         NaN       NaN                           NaN   \n",
              "3       NaN       NaN         NaN       NaN                           NaN   \n",
              "4       NaN       NaN         NaN       NaN                           NaN   \n",
              "\n",
              "   2011_comm  2012_comm  2013_comm  2014_comm  2015_comm  \n",
              "0          0          0          0          0          0  \n",
              "1          0          0          0          0          0  \n",
              "2          0          0          0          0          0  \n",
              "3          0          0          0          0          0  \n",
              "4          0          0          0          0          0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAf4W4Pxv7mQ",
        "outputId": "e0dba5cb-b63e-4617-9d19-7b25e1757727"
      },
      "source": [
        "# number of unique directors with unique bios in the dataset\n",
        "all_bios_df_unique.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5276, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tW97yljSsLo"
      },
      "source": [
        "# Creating baseline models\n",
        "\n",
        "Two different baseline models will be used to compare my model results to later on. The first model takes the Dummy estimator from sklearn and uses its stratified option which makes random predictions in accordance with the training set distribution of class labels.\n",
        "\n",
        "The second model is the [zero-shot-classification model](https://github.com/huggingface/transformers/pull/5760) implemented in a pipeline version by Hugging Face. This model can predict user-specified labels for text which the model was not trained on. Multi-label classification is supported. The maximum token length is set to 1024, which means that some bios will be truncated and information may be lost. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBmhv4BGfcBr"
      },
      "source": [
        "## DummyClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XZUcyOiq4gu"
      },
      "source": [
        "# the dummyclassifier implementation is based on https://machinelearningmastery.com/naive-classifiers-imbalanced-classification-metrics/\n",
        "def eval_models(X, y, name, model):\n",
        "    '''\n",
        "    Function to evaluate the different baseline models.\n",
        "    The cross_val_score function cannot be used because stratification only\n",
        "    works with single-label cases. In this multi-label case I have to stratify\n",
        "    the data manually based on the environmental label. A combination of the label\n",
        "    cannot be used because then the least populated case that is both social and\n",
        "    environmental [1,1] appears only twice in the dataset\n",
        "    Args: X = str; biographies\n",
        "          y = int; labels\n",
        "          name = str; name of the model\n",
        "          model = object; model\n",
        "    Returns: social_score, environmental_score = float\n",
        "    '''\n",
        "\n",
        "    social_score = []\n",
        "    environmental_score = []\n",
        "\n",
        "    # getting the start time\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    # instantiate the Kfold object\n",
        "    cross_val = RepeatedStratifiedKFold(n_splits=4, n_repeats=5, random_state=42)\n",
        "    for train_index, val_index in cross_val.split(X, y['environmental']):\n",
        "        model.fit(X.iloc[train_index], y.iloc[train_index])\n",
        "        predictions = model.predict(X.iloc[val_index])\n",
        "        scores = f1_score(y.iloc[val_index], predictions, average=None)\n",
        "        social_score.append(scores[0])\n",
        "        environmental_score.append(scores[1])\n",
        "\n",
        "    # get final time\n",
        "    end_time = datetime.now()\n",
        "    print('Total running time of', name, (end_time - start_time).total_seconds())   \n",
        "\n",
        "    return social_score, environmental_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEKUe_GNznCJ"
      },
      "source": [
        "def get_models():\n",
        "    '''\n",
        "    Function to instantiate different Dummy Classifier models\n",
        "    Args: None\n",
        "    Returns: \n",
        "    '''\n",
        "    models, names = [], []\n",
        "    # Uniform implementation\n",
        "    models.append(DummyClassifier(strategy='uniform', random_state=42))\n",
        "    names.append('Uniform random guess')\n",
        "    # Stratified implementation\n",
        "    models.append(DummyClassifier(strategy='stratified', random_state=42))\n",
        "    names.append('Stratified')\n",
        "    # Constant implementation\n",
        "    models.append(DummyClassifier(strategy='constant', constant=[0,0], random_state=42))\n",
        "    names.append('Constant')\n",
        "\n",
        "    return models, names\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu6cNwYG0n8J"
      },
      "source": [
        "# prepare the data\n",
        "X = all_rev_df['bio']\n",
        "y = all_rev_df[['social', 'environmental']]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA1aGU6R03fJ",
        "outputId": "832d7e87-70c5-4fbd-8c5d-c6b5541936eb"
      },
      "source": [
        "# evaluate the different naive baseline models\n",
        "models, names = get_models()\n",
        "\n",
        "for name, model in zip(names, models):\n",
        "    social_score, environmental_score = eval_models(X, y, name, model)\n",
        "    print('Baseline type:', name, 'Social:', 'Average f1 score:', np.mean(social_score), 'Standard deviation:', np.std(social_score))\n",
        "    print('Baseline type:', name, 'Environmental:', 'Average f1 score:', np.mean(environmental_score), 'Standard deviation:', np.std(environmental_score))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total running time of Uniform random guess 0.05807\n",
            "Baseline type: Uniform random guess Social: Average f1 score: 0.42531900327758426 Standard deviation: 0.10814917264561477\n",
            "Baseline type: Uniform random guess Environmental: Average f1 score: 0.17941176470588233 Standard deviation: 0.08208991609972273\n",
            "Total running time of Stratified 0.06031\n",
            "Baseline type: Stratified Social: Average f1 score: 0.32163636001970264 Standard deviation: 0.08865527222440235\n",
            "Baseline type: Stratified Environmental: Average f1 score: 0.11111111111111112 Standard deviation: 0.11111111111111112\n",
            "Total running time of Constant 0.062293\n",
            "Baseline type: Constant Social: Average f1 score: 0.0 Standard deviation: 0.0\n",
            "Baseline type: Constant Environmental: Average f1 score: 0.0 Standard deviation: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XPhSED9ffYr"
      },
      "source": [
        "## Zero-shot Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIVbZPdiUjpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65235285-e155-4e72-a7dd-b1e2f3172de6"
      },
      "source": [
        "# instantiate classifier\n",
        "zero_shot_classifier = pipeline('zero-shot-classification', device=0) # to utilize GPU\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['model.encoder.version', 'model.decoder.version']\n",
            "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
            "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKeg7mkzfZ_s"
      },
      "source": [
        "# specify labels\n",
        "candidate_labels = ['social', 'environmental', 'general']\n",
        "# to increase the performance of the zero shot learning, we can add a hypothesis_template\n",
        "# which gives a hint to the model to understand what broad category to look for\n",
        "# hypothesis_template = 'This person has career experience in {} areas.'\n",
        "hypothesis_template = 'This example is {}.'\n",
        "# default hypothesis is 'This example is {class_name}.'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6BQvRKggIys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e9b6f8-c946-40e2-dcc2-d5ede0a7bc40"
      },
      "source": [
        "# iterate through the cross_val datasets and predict and evaluate the bios\n",
        "social_pred_list = []\n",
        "environmental_pred_list = []\n",
        "social_score_list = []\n",
        "environmental_score_list = []\n",
        "\n",
        "# getting the start time\n",
        "start_time = datetime.now()\n",
        "\n",
        "# instantiate the Kfold object\n",
        "cross_val = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "# convert the two labels into one to be able to use stratified Kfold\n",
        "for train_index, val_index in cross_val.split(X, y['environmental']):\n",
        "\n",
        "    social_pred_list = []\n",
        "    environmental_pred_list = []\n",
        "\n",
        "    for i, text in enumerate(X.iloc[val_index]):\n",
        "        predictions = zero_shot_classifier(text, candidate_labels, hypothesis_template=hypothesis_template, multi_class=True)\n",
        "        predictions = predictions['scores'][:2]\n",
        "        predictions = [1 if x > 0.5 else 0 for x in predictions]\n",
        "        social_pred_list.append(predictions[0])\n",
        "        environmental_pred_list.append(predictions[1])\n",
        "\n",
        "    social_score_list.append(f1_score(y.iloc[val_index]['social'], social_pred_list))\n",
        "    environmental_score_list.append(f1_score(y.iloc[val_index]['environmental'], environmental_pred_list))\n",
        "\n",
        "# get final time\n",
        "end_time = datetime.now()\n",
        "print('Total running time of zero-shot classification', (end_time - start_time).total_seconds())\n",
        "\n",
        "print('Social f1 score:', np.mean(social_score_list))\n",
        "print('Environmental f1 score:', np.mean(environmental_score_list))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total running time of zero-shot classification 193.534237\n",
            "Social f1 score: 0.5339294185263196\n",
            "Environmental f1 score: 0.21533872340124213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6GFNh6L9z6u"
      },
      "source": [
        "# Defining classes necessary for fine-tuning\n",
        "\n",
        "I will first use the detaul max_token_len of Longformer which is 4096 to determine how long the longest tokenized bio actually is. I will use this maximum value as the max_token_len. This way I ensure that first, I am not going to cut off important information if the max_token_len is to short. And second, I will use less compute and RAM during the fine-tuning process if I don't unnecessarily use the default max_token_len."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_wmZakNk28p"
      },
      "source": [
        "# This will be an alternative to the BERT model to account for the length of the bios\n",
        "# which go beyond BERTs max length of 512 tokens\n",
        "model_name = 'allenai/longformer-base-4096'\n",
        "num_labels = 2\n",
        "# for longformer model\n",
        "max_token_len = 4096 # this is the default token length\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHjuSL6UNTGO"
      },
      "source": [
        "# create class for custom dataset based on https://huggingface.co/transformers/custom_datasets.html and this https://www.youtube.com/watch?v=wG2J_MJEjSQ\n",
        "class DirectorDataset(torch.utils.data.Dataset):\n",
        "    '''\n",
        "    Class to create a PyTorch Dataset which will be \n",
        "    necessary to pass the tokens to the fine-tuning trainer\n",
        "    It will read in the data in dataframe format and then tokenize them\n",
        "    '''\n",
        "    def __init__(self, data: pd.DataFrame, tokenizer: AutoTokenizer, max_token_len):\n",
        "        '''\n",
        "        Instantiate the object\n",
        "        '''\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        '''\n",
        "        Structure the data into a dictionary containing input_ids, \n",
        "        attention_masks, and idx\n",
        "        '''\n",
        "        row = self.data.iloc[idx]\n",
        "        feature = row.bio\n",
        "        labels = row[['social', 'environmental']]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            feature,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_token_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return dict(\n",
        "            feature=feature, \n",
        "            input_ids=encoding['input_ids'].flatten(),\n",
        "            attention_mask=encoding['attention_mask'].flatten(),\n",
        "            labels=torch.FloatTensor(labels)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Show the length of the dataset\n",
        "        '''\n",
        "        return len(self.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNRSopBzUWca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f994626-836d-4e6e-cb91-91450168e4cf"
      },
      "source": [
        "# add placeholder columns for the labels to be able to use the DirectorDataset class\n",
        "all_bios_df_unique['social'] = 0\n",
        "all_bios_df_unique['environmental'] = 0\n",
        "\n",
        "# tokenize the entire bio dataset with the default token length of 4096\n",
        "total_set = DirectorDataset(all_bios_df_unique, tokenizer, max_token_len=max_token_len)\n",
        "\n",
        "# create variable to save largest end_token\n",
        "largest_end_token = 0\n",
        "all_len = []\n",
        "\n",
        "# iterate through all samples in the dataset and determine the first 0 in the \n",
        "# attention_mask which will represent the end of the tokenized biography because\n",
        "# the 0s stand for padding added to each tokenized item\n",
        "for item in total_set:\n",
        "    end_token = item['attention_mask'].flatten().tolist().index(0)\n",
        "    all_len.append(end_token)\n",
        "    # check whether the end_token is longer than the previously longest bio\n",
        "    if end_token > largest_end_token:\n",
        "        largest_end_token = end_token\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "# print the end_token of the longest biography\n",
        "print('Longest token is', largest_end_token)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Longest token is 1765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SupLz_AcC3eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac94d09-78a6-482f-9242-cd80765b019a"
      },
      "source": [
        "# check how many samples are longer than a certain threshold\n",
        "max_token_len = 1700\n",
        "all_len_df = pd.DataFrame(data=all_len, columns=['len'])\n",
        "absolute_above = all_len_df[all_len_df['len'] > max_token_len].count()\n",
        "print('%.2f' % (absolute_above / all_bios_df_unique.shape[0] * 100), '% are longer than', max_token_len, 'tokens')\n",
        "print(absolute_above.values[0], ' biographies are longer than', max_token_len, 'tokens')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02 % are longer than 1700 tokens\n",
            "1  biographies are longer than 1700 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jWxMA10qMZU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}